{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "actual-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "### METHODS TO READ DATA IN ###\n",
    "import sys\n",
    "from provided_code.data_loader import DataLoader #provided by the challenge creators\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Pre-processing method: correctly aligns the images\n",
    "# and concatenates them into one list\n",
    "def pre_processing(dict_images):\n",
    "    \n",
    "    # Data in OpenKBP dataset is (h, w, -z, c) or (y, x, -z, c)\n",
    "    # Change to (c, z, x, y)\n",
    "    OAR_all = dict_images['structure_masks'][:,:,::-1,:].transpose(3,2,1,0)\n",
    "    CT = dict_images['ct'][:,:,::-1,:].transpose(3,2,1,0)\n",
    "    dose = dict_images['dose'][:,:,::-1,:].transpose(3,2,1,0)\n",
    "    possible_dose_mask = dict_images['possible_dose_mask'][:,:,::-1,:].transpose(3,2,1,0)\n",
    "\n",
    "    list_images = [np.concatenate((OAR_all, CT), axis=0),  # Input\n",
    "                   dose,  # Label\n",
    "                   possible_dose_mask]\n",
    "    return list_images\n",
    "\n",
    "# Custom dataset: fetches correct patiets per phase\n",
    "# and pre-processes with above method\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, num_samples_per_epoch, phase):\n",
    "        # 'train' or 'val'\n",
    "        self.phase = phase\n",
    "        self.num_samples_per_epoch = num_samples_per_epoch\n",
    "\n",
    "        self.list_case_id = {'train': ['provided-data/train-pats/pt_' + str(i) for i in range(1, 201)],\n",
    "                             'val': ['provided-data/validation-pats/pt_' + str(i) for i in range(201, 241)],\n",
    "                             'test': ['provided-data/test-pats/pt_' + str(i) for i in range(241, 341)]}[phase]\n",
    "        random.shuffle(self.list_case_id)\n",
    "        self.dl = DataLoader(self.list_case_id)\n",
    "        self.sum_case = len(self.list_case_id)\n",
    "\n",
    "    def __getitem__(self, index_):\n",
    "        dict_images = self.dl.load_and_shape_data(self.list_case_id[index_])\n",
    "        list_images = pre_processing(dict_images)\n",
    "        for i in range(len(list_images)):\n",
    "            list_images[i] = torch.from_numpy(list_images[i].copy()).float()\n",
    "        return list_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples_per_epoch\n",
    "\n",
    "# Method to get loader: builds dataloaders using custom dataset\n",
    "# num_samples_per_epoch indiciates how many samples are looked at\n",
    "# per epoch. \n",
    "def get_loader(train_bs=1, val_bs=1, train_num_samples_per_epoch=4, val_num_samples_per_epoch=4, num_works=0):\n",
    "    train_dataset = MyDataset(num_samples_per_epoch=train_num_samples_per_epoch, phase='train')\n",
    "    val_dataset = MyDataset(num_samples_per_epoch=val_num_samples_per_epoch, phase='val')\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=train_bs, shuffle=True, num_workers=num_works,\n",
    "                                   pin_memory=False)\n",
    "    val_loader = data.DataLoader(dataset=val_dataset, batch_size=val_bs, shuffle=False, num_workers=num_works,\n",
    "                                 pin_memory=False)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lasting-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL ###\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Basic 3D convolution block: 3x3x3 convolution\n",
    "# with stride=1, padding=1. Followed by instance\n",
    "# noramlization and ReLU\n",
    "class SingleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        self.single_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride, bias=True),\n",
    "            nn.InstanceNorm3d(out_ch, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.single_conv(x)\n",
    "\n",
    "# Upsampling block: first applies trilinear upsampling,\n",
    "# then 3x3x3 convolution with stride=1, padding=1. Followed\n",
    "# by instance noramlization and ReLU\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpConv, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1, stride=1, bias=True),\n",
    "            nn.InstanceNorm3d(out_ch, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "# Set of downsampling blocks: Uses basic\n",
    "# convolution block sequence with stride=2\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_ch, list_ch):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            SingleConv(in_ch, list_ch[1], kernel_size=3, stride=1, padding=1),\n",
    "            SingleConv(list_ch[1], list_ch[1], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            SingleConv(list_ch[1], list_ch[2], kernel_size=3, stride=2, padding=1),\n",
    "            SingleConv(list_ch[2], list_ch[2], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            SingleConv(list_ch[2], list_ch[3], kernel_size=3, stride=2, padding=1),\n",
    "            SingleConv(list_ch[3], list_ch[3], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.encoder_4 = nn.Sequential(\n",
    "            SingleConv(list_ch[3], list_ch[4], kernel_size=3, stride=2, padding=1),\n",
    "            SingleConv(list_ch[4], list_ch[4], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.encoder_5 = nn.Sequential(\n",
    "            SingleConv(list_ch[4], list_ch[5], kernel_size=3, stride=2, padding=1),\n",
    "            SingleConv(list_ch[5], list_ch[5], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_encoder_1 = self.encoder_1(x)\n",
    "        out_encoder_2 = self.encoder_2(out_encoder_1)\n",
    "        out_encoder_3 = self.encoder_3(out_encoder_2)\n",
    "        out_encoder_4 = self.encoder_4(out_encoder_3)\n",
    "        out_encoder_5 = self.encoder_5(out_encoder_4)\n",
    "\n",
    "        return [out_encoder_1, out_encoder_2, out_encoder_3, out_encoder_4, out_encoder_5]\n",
    "\n",
    "# Set of upsampling blocks: uses upsampling\n",
    "# blocks and basic blocks as described above\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, list_ch):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.upconv_4 = UpConv(list_ch[5], list_ch[4])\n",
    "        self.decoder_conv_4 = nn.Sequential(\n",
    "            SingleConv(2 * list_ch[4], list_ch[4], kernel_size=3, stride=1, padding=1),\n",
    "            SingleConv(list_ch[4], list_ch[4], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.upconv_3 = UpConv(list_ch[4], list_ch[3])\n",
    "        self.decoder_conv_3 = nn.Sequential(\n",
    "            SingleConv(2 * list_ch[3], list_ch[3], kernel_size=3, stride=1, padding=1),\n",
    "            SingleConv(list_ch[3], list_ch[3], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.upconv_2 = UpConv(list_ch[3], list_ch[2])\n",
    "        self.decoder_conv_2 = nn.Sequential(\n",
    "            SingleConv(2 * list_ch[2], list_ch[2], kernel_size=3, stride=1, padding=1),\n",
    "            SingleConv(list_ch[2], list_ch[2], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.upconv_1 = UpConv(list_ch[2], list_ch[1])\n",
    "        self.decoder_conv_1 = nn.Sequential(\n",
    "            SingleConv(2 * list_ch[1], list_ch[1], kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, out_encoder):\n",
    "        out_encoder_1, out_encoder_2, out_encoder_3, out_encoder_4, out_encoder_5 = out_encoder\n",
    "\n",
    "        out_decoder_4 = self.decoder_conv_4(\n",
    "            torch.cat((self.upconv_4(out_encoder_5), out_encoder_4), dim=1)\n",
    "        )\n",
    "        out_decoder_3 = self.decoder_conv_3(\n",
    "            torch.cat((self.upconv_3(out_decoder_4), out_encoder_3), dim=1)\n",
    "        )\n",
    "        out_decoder_2 = self.decoder_conv_2(\n",
    "            torch.cat((self.upconv_2(out_decoder_3), out_encoder_2), dim=1)\n",
    "        )\n",
    "        out_decoder_1 = self.decoder_conv_1(\n",
    "            torch.cat((self.upconv_1(out_decoder_2), out_encoder_1), dim=1)\n",
    "        )\n",
    "\n",
    "        return out_decoder_1\n",
    "\n",
    "# Define the overall structure of U-Net: uses\n",
    "# set of downsampling and upsampling blocks as\n",
    "# described above\n",
    "class BaseUNet(nn.Module):\n",
    "    def __init__(self, in_ch, list_ch):\n",
    "        super(BaseUNet, self).__init__()\n",
    "        self.encoder = Encoder(in_ch, list_ch)\n",
    "        self.decoder = Decoder(list_ch)\n",
    "\n",
    "        # init\n",
    "        self.initialize()\n",
    "\n",
    "    @staticmethod\n",
    "    def init_conv_IN(modules):\n",
    "        for m in modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.)\n",
    "            elif isinstance(m, nn.InstanceNorm3d):\n",
    "                nn.init.constant_(m.weight, 1.)\n",
    "                nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "    def initialize(self):\n",
    "        self.init_conv_IN(self.encoder.modules)\n",
    "        self.init_conv_IN(self.decoder.modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_encoder = self.encoder(x)\n",
    "        out_decoder = self.decoder(out_encoder)\n",
    "\n",
    "        return out_decoder\n",
    "\n",
    "# Define Model: U-Net, with output layer: a 1x1x1 convolution\n",
    "# in_ch, out_ch are the input/output channels (11 and 1)\n",
    "# list_ch are the number of feature maps of blocks in U-Net\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, list_ch):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.net = BaseUNet(in_ch, list_ch)\n",
    "        self.conv_out = nn.Conv3d(list_ch[1], out_ch, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_net = self.net(x)\n",
    "        output = self.conv_out(out_net)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sought-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOSS FUNCTION ###\n",
    "import torch.nn as nn\n",
    "\n",
    "# Custom L1 loss function to zoom in on the voxels\n",
    "# of possible dose mask only.\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.L1_loss_func = nn.L1Loss(reduction='mean')\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        gt_dose = gt[0]\n",
    "        possible_dose_mask = gt[1]\n",
    "\n",
    "        pred = pred[possible_dose_mask > 0]\n",
    "        gt_dose = gt_dose[possible_dose_mask > 0]\n",
    "\n",
    "        L1_loss = self.L1_loss_func(pred, gt_dose)\n",
    "        return L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frozen-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING LOOP ###\n",
    "import time\n",
    "\n",
    "# Function to train the model: Takes in\n",
    "# a model, dataloader, optimizer, scheduler, and loss function.\n",
    "# num_epochs controls max number of epochs the loop is run for\n",
    "# verbose for logging\n",
    "def train_model(model, dataloader, optimizer, scheduler, loss_fn, num_epochs = 50, verbose = False):\n",
    "    loss_dict = {'train':[],'val':[]}\n",
    "    best_loss = 500\n",
    "    phases = ['train','val']\n",
    "    since = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        if verbose or (i%10 == 0):\n",
    "            print('Epoch: {}/{}'.format(i+1, num_epochs))\n",
    "            print('-'*10)\n",
    "        for p in phases:\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()\n",
    "                image = data[0].to(device)\n",
    "                dose = data[1].to(device)\n",
    "                pdm = data[2].to(device)\n",
    "                label = [dose,pdm]\n",
    "                output = model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "                num_imgs = image.size()[0]\n",
    "                running_loss += loss.item()*num_imgs\n",
    "                running_total += num_imgs\n",
    "                if p== 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            epoch_loss = float(running_loss/running_total)\n",
    "            if verbose or (i%10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f}'.format(p, epoch_loss))\n",
    "            \n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            if p == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = model.state_dict()\n",
    "            else:\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baking-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define model, loss, optimizer, scheduler, dataloader for training loop ###\n",
    "model = Model(in_ch=11, out_ch=1, list_ch=[-1, 16, 32, 64, 128, 256])\n",
    "device = torch.device('cuda')\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "loss = Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80000, eta_min=1e-7, last_epoch=-1)\n",
    "bs = 1\n",
    "dataloader = {}\n",
    "dataloader['train'] , dataloader['val'] = get_loader(\n",
    "        train_bs=bs,\n",
    "        val_bs=bs,\n",
    "        train_num_samples_per_epoch=200,  \n",
    "        val_num_samples_per_epoch=40,\n",
    "        num_works=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sticky-midnight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "----------\n",
      "Phase:train, epoch loss: 21.9143\n",
      "Phase:val, epoch loss: 21.3063\n",
      "Epoch: 2/50\n",
      "----------\n",
      "Phase:train, epoch loss: 20.9893\n",
      "Phase:val, epoch loss: 20.7821\n",
      "Epoch: 3/50\n",
      "----------\n",
      "Phase:train, epoch loss: 20.5120\n",
      "Phase:val, epoch loss: 20.3260\n",
      "Epoch: 4/50\n",
      "----------\n",
      "Phase:train, epoch loss: 19.7598\n",
      "Phase:val, epoch loss: 19.7626\n",
      "Epoch: 5/50\n",
      "----------\n",
      "Phase:train, epoch loss: 19.3305\n",
      "Phase:val, epoch loss: 19.3231\n",
      "Epoch: 6/50\n",
      "----------\n",
      "Phase:train, epoch loss: 18.8603\n",
      "Phase:val, epoch loss: 18.8134\n",
      "Epoch: 7/50\n",
      "----------\n",
      "Phase:train, epoch loss: 18.4156\n",
      "Phase:val, epoch loss: 18.3723\n",
      "Epoch: 8/50\n",
      "----------\n",
      "Phase:train, epoch loss: 17.7459\n",
      "Phase:val, epoch loss: 17.8372\n",
      "Epoch: 9/50\n",
      "----------\n",
      "Phase:train, epoch loss: 17.2853\n",
      "Phase:val, epoch loss: 17.2531\n",
      "Epoch: 10/50\n",
      "----------\n",
      "Phase:train, epoch loss: 16.8403\n",
      "Phase:val, epoch loss: 16.8154\n",
      "Epoch: 11/50\n",
      "----------\n",
      "Phase:train, epoch loss: 16.1692\n",
      "Phase:val, epoch loss: 16.3642\n",
      "Epoch: 12/50\n",
      "----------\n",
      "Phase:train, epoch loss: 15.4286\n",
      "Phase:val, epoch loss: 15.7790\n",
      "Epoch: 13/50\n",
      "----------\n",
      "Phase:train, epoch loss: 15.0097\n",
      "Phase:val, epoch loss: 15.2884\n",
      "Epoch: 14/50\n",
      "----------\n",
      "Phase:train, epoch loss: 14.4116\n",
      "Phase:val, epoch loss: 14.5922\n",
      "Epoch: 15/50\n",
      "----------\n",
      "Phase:train, epoch loss: 14.0215\n",
      "Phase:val, epoch loss: 14.1939\n",
      "Epoch: 16/50\n",
      "----------\n",
      "Phase:train, epoch loss: 13.1544\n",
      "Phase:val, epoch loss: 13.6719\n",
      "Epoch: 17/50\n",
      "----------\n",
      "Phase:train, epoch loss: 12.6319\n",
      "Phase:val, epoch loss: 13.0216\n",
      "Epoch: 18/50\n",
      "----------\n",
      "Phase:train, epoch loss: 12.0018\n",
      "Phase:val, epoch loss: 12.6163\n",
      "Epoch: 19/50\n",
      "----------\n",
      "Phase:train, epoch loss: 11.3417\n",
      "Phase:val, epoch loss: 11.7900\n",
      "Epoch: 20/50\n",
      "----------\n",
      "Phase:train, epoch loss: 10.6676\n",
      "Phase:val, epoch loss: 11.4846\n",
      "Epoch: 21/50\n",
      "----------\n",
      "Phase:train, epoch loss: 10.2863\n",
      "Phase:val, epoch loss: 10.8933\n",
      "Epoch: 22/50\n",
      "----------\n",
      "Phase:train, epoch loss: 9.7917\n",
      "Phase:val, epoch loss: 10.3203\n",
      "Epoch: 23/50\n",
      "----------\n",
      "Phase:train, epoch loss: 9.0258\n",
      "Phase:val, epoch loss: 9.7732\n",
      "Epoch: 24/50\n",
      "----------\n",
      "Phase:train, epoch loss: 8.3947\n",
      "Phase:val, epoch loss: 9.4985\n",
      "Epoch: 25/50\n",
      "----------\n",
      "Phase:train, epoch loss: 7.9697\n",
      "Phase:val, epoch loss: 8.9354\n",
      "Epoch: 26/50\n",
      "----------\n",
      "Phase:train, epoch loss: 7.4602\n",
      "Phase:val, epoch loss: 8.5908\n",
      "Epoch: 27/50\n",
      "----------\n",
      "Phase:train, epoch loss: 7.1372\n",
      "Phase:val, epoch loss: 8.4168\n",
      "Epoch: 28/50\n",
      "----------\n",
      "Phase:train, epoch loss: 6.9659\n",
      "Phase:val, epoch loss: 7.9101\n",
      "Epoch: 29/50\n",
      "----------\n",
      "Phase:train, epoch loss: 6.3952\n",
      "Phase:val, epoch loss: 7.8347\n",
      "Epoch: 30/50\n",
      "----------\n",
      "Phase:train, epoch loss: 6.1716\n",
      "Phase:val, epoch loss: 7.7939\n",
      "Epoch: 31/50\n",
      "----------\n",
      "Phase:train, epoch loss: 5.9577\n",
      "Phase:val, epoch loss: 7.9087\n",
      "Epoch: 32/50\n",
      "----------\n",
      "Phase:train, epoch loss: 5.9293\n",
      "Phase:val, epoch loss: 7.2644\n",
      "Epoch: 33/50\n",
      "----------\n",
      "Phase:train, epoch loss: 5.6371\n",
      "Phase:val, epoch loss: 7.0612\n",
      "Epoch: 34/50\n",
      "----------\n",
      "Phase:train, epoch loss: 5.3800\n",
      "Phase:val, epoch loss: 6.8915\n",
      "Epoch: 35/50\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "### Train the model, 50 epochs ###\n",
    "model, loss_dict = train_model(model, dataloader, optimizer, scheduler, loss, num_epochs=50, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save model locally, name reflects configuration tested ###\n",
    "torch.save(model,'lr3e-4_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Also save the losses for ease of access ###\n",
    "import pickle\n",
    "f = open('lr3e-4_loss.pkl','wb')\n",
    "pickle.dump(loss_dict,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liked-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the dose score on test set ###\n",
    "import torch.utils.data as data\n",
    "# Define test dataset and dataloader\n",
    "test_dataset = MyDataset(num_samples_per_epoch=100, phase='test')\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, num_workers=0,pin_memory=False)\n",
    "# Empty lists to save images for visualization later: requires a lot of memory\n",
    "mads = []\n",
    "cts= []\n",
    "doses = []\n",
    "preds = []\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():\n",
    "        image = data[0]\n",
    "        cts.append(image.numpy()[0,-1,:,:,:])\n",
    "        dose = data[1].numpy()        \n",
    "        pdm = data[2].numpy()\n",
    "        doses.append(np.where(pdm>0,dose,0))\n",
    "        preds.append(np.where(pdm>0,dose,0))\n",
    "        pred = model(image).cpu().numpy()        \n",
    "        pred = pred[pdm > 0]\n",
    "        dose = dose[pdm > 0]\n",
    "        \n",
    "        mads.append(np.mean(np.abs(pred-dose)))\n",
    "        \n",
    "dose_score = np.mean(mads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "altered-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dose score is: 3.729331\n"
     ]
    }
   ],
   "source": [
    "### Print out test dose score ###\n",
    "print('Dose score is: ' + str(dose_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banner-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max MAE in Test Set is: 9.856223106384277 at index 82.\n",
      "The min MAE in Test Set is: 1.981579065322876 at index 14.\n"
     ]
    }
   ],
   "source": [
    "### Print out lowest/highest MAE in test set ###\n",
    "import numpy as np\n",
    "print(f'The max MAE in Test Set is: {np.amax(mads)} at index {np.argmax(mads)}.')\n",
    "print(f'The min MAE in Test Set is: {np.amin(mads)} at index {np.argmin(mads)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stable-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get visuals for Figure 5 of paper ###\n",
    "### Draws CT image and dose ground truth or prediction ###\n",
    "### For highest/lowest MAE index ###\n",
    "from mayavi import mlab\n",
    "\n",
    "dose = doses[14][0,0,:,:,:].transpose(2,0,1)\n",
    "ct = cts[14].transpose(2,0,1)\n",
    "mlab.pipeline.volume(mlab.pipeline.scalar_field(ct),color=(0,0,1))\n",
    "mlab.pipeline.volume(mlab.pipeline.scalar_field(dose))\n",
    "\n",
    "\n",
    "mlab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
